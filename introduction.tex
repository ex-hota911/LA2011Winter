\section{Introduction}

Let $g \colon [0,1] \times \R \to \R$ be continuous 
and consider the following differential equation: 
\begin{align}
 \label{eq:ode}
 h(0) & = 0, &
 \D h(t) & = g(t,h(t)) \quad t \in [0,1], 
\end{align}
where $\D h$ denotes the derivative of $h$. 
How complex can the solution~$h$ be, 
assuming that $g$ is polynomial-time computable? 
Here, the polynomial-time computability 
and other notions of complexity 
are from the field of 
\emph{Computable Analysis}~\cite{weihrauch00:_comput_analy}
and measure how hard it is to 
approximate real functions with specified precisions 
(Section~\ref{section: preliminaries}). 

If we put no assumption on $g$ other than being polynomial-time computable, 
the solution~$h$ (which is not unique in general) can be non-computable. 
Table~\ref{table:related} summarizes known results about 
the complexity of $h$ under various assumptions on $g$, 
with the assumptions getting stronger as we go down. 
In particular, if $g$ is (globally) Lipschitz continuous, 
then the (unique) solution $h$ is known to be 
polynomial-space computable but still can be 
$\classPSPACE$-hard \cite{kawamura2010lipschitz}. 
In this paper, we study the complexity of $h$ 
when we put stronger assumptions about 
the smoothness of $g$. 

\begin{table}
\renewcommand\arraystretch{1.3}
\begin{center}
 \caption{The complexity of the solution $h$ of \eqref{eq:ode}
 assuming $g$ is polynomial-time computable.}
 \label{table:related}
 \begin{tabular}{lll}
  Assumptions & Upper bounds & Lower bounds \\
  \hline
   --- & --- & can be all non-computable \cite{pour1979computable} \\
  $h$ is the unique solution & computable \cite{coddington1955theory}
  & can take arbitrarily long time \cite{ko1983computational, miller1970recursive} \\
  the Lipschitz condition  & polynomial-space \cite{ko1983computational}
      &	can be $\classPSPACE$-hard \cite{kawamura2010lipschitz}\\
  $g$ is of class $\classC ^{(\infty, 1)}$ & polynomial-space 
      & \parbox[t]{14zw}{can be $\classPSPACE$-hard\\{}(Theorem~\ref{DifferentiableIsPspace})} \\
  \parbox[t]{14zw}{$g$ is of class $\classC ^{(\infty, k)}$\\{}(for any constant $k$)}
  & polynomial-space & \parbox[t]{14zw}{can be $\classCH$-hard\\{}(Theorem~\ref{KTimesIsCH})} \\
  $g$ is analytic
  & polynomial-time \cite{muller1987uniform, ko1988computing} 
  & ---
 \end{tabular}
\end{center}
\end{table}

In numerical analysis, 
knowledge about smoothness of the input function 
(such as being differentiable enough times) 
is often beneficial 
in applying certain algorithms or simplifying their analysis.
However, to our knowledge
this casual understanding that smoothness is good 
has not been 
rigorously substantiated in terms of 
computational complexity theory. 
This motivates us to ask whether, 
for our differential equation \eqref{eq:ode}, 
smoothness helps to reduce the complexity of the solution. 

At the extreme is the case where $g$ is analytic: 
as the last row of the table shows, 
$h$ can then be shown to be polynomial-time computable 
by the Taylor series methods. 
Thus our interest is in 
the cases between Lipschitz and analytic 
(the fourth and fifth rows in the table). 
We say that $g$ is of class $\classC ^{(i, j)}$
if the partial derivative $\D ^{(i, j)} g$ 
(often also denoted $\partial ^{i + j} g (t, y) / \partial t ^i \partial y ^j$)
exists and is continuous%
\footnote{%
Another common terminology is to say that $g$ is of class $\classC ^k$
if it is of class $\classC ^{(i,j)}$ 
for all $i$, $j$ with $i + j \leq k$.}; 
it is said to be of class $\classC ^{(\infty, j)}$ if
it is of class $\classC ^{(i, j)}$ for all $i \in \N$. 

\begin{theorem}
 \label{DifferentiableIsPspace}
There is a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, 1)}$ such that
the equation \eqref{eq:ode} has a 
$\classPSPACE$-hard solution $h \colon [0, 1] \to \R$. 
 \end{theorem}

 \begin{theorem}
  \label{KTimesIsCH}
Let $k$ be a positive integer. 
There is a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, k)}$ such that
the equation \eqref{eq:ode} has a 
$\classCH$-hard solution $h \colon [0, 1] \to \R$, 
where $\classCH \subseteq \classPSPACE$ is the 
Counting Hierarchy (see Section~\ref{subsection: counting hierarchy}). 
 \end{theorem}

ここで $g \colon [0,1] \times \R \to \R$ でなく
$g \colon [0,1] \times [-1, 1] \to \R$ と書いたのは, 
本稿では実関数の多項式時間計算可能性を, 
定義域が有界閉領域のときにのみ定義するからである. 
このため $h$ が区間 $[-1, 1]$ の外に値を取ることがあると
方程式(\ref{eq:ode})が意味をなさなくなるが, 
定理\ref{DifferentiableIsPspace}において $h$ が解であるというのは, 
任意の $t \in [0, 1]$ について $h (t) \in [-1, 1]$ が満たされることも含めて述べている.
なお両定理とも Lipschitz 条件よりも強い仮定を置いているため, 
そのような $h$ は $g$ に対して, 存在すれば唯一である. 

本稿のように対象を滑らかな関数に制限することによる計算量の変化について,
常微分方程式以外の問題では次のような否定的な結果がある.
多項式時間計算可能な関数から積分により得られる関数は, 
もとの関数を無限回微分可能なものに限っても
なお一般の場合と同じく$\classNumberP$困難である. 
\cite[定理5.33]{ko1991complexity}.
最大化でも同様に, 
無限回微分可能な関数に限っても一般の場合と同じく
$\classNP$困難である\cite[定理3.7]{ko1991complexity}%
\footnote{%
ただし葛\cite[定理3.7]{ko1991complexity}の証明において関数$f$を
\[f(x) = 
\begin{cases}
 u_s & \text{if not } R(s,t) \\
 u_s + 2^{-(p(n)+2n+1)\cdot n} \cdot h_1(2^{p(n)+2n+1} (x - y_{s,t})) & \text{if } R(s,t)
\end{cases}\]
に修正する必要がある.
}
(なお対象を解析的な関数に限ると, 
やはり級数を用いた議論により, 
これらは多項式時間計算可能になる). 
一方常微分方程式については, 
定理\ref{KTimesIsCH}は各$k$についてそれぞれ成立つが, 
$g$が$(\infty, \infty)$回微分可能であると仮定したときの
$h$の計算量については依然不明である. 

\subsubsection*{Notation}
Let $\N$ denote the set of natural numbers,
$\Q$ denote the set of rational numbers 
and $\R$ denote the set of real numbers.

Let $A$ and $B$ be bounded closed interval in $\R$.
We denote $|f|$ as $\sup_{x \in A} f(x)$ where $f \colon A \to \R$.


A function $f \colon A \to \R$ is \emph{$i$-times continuously differentiable}
if there exist the derivatives $\D f, \D^2 f, \dots, \D^i f$ and all of them are continuous.
We write $\classC^k_A$ for the set of $k$-times continuously differentiable functions from $A$ to $\R$,
and abbreviate it as $\classC^k$ if the domain $A$ is obvious.
A function $g \colon A \times B \to \R$ is \emph{$(i, j)$-times continuously  differentiable}
if for each $n \in \{0, \dots, i\}$ and $m \in \{0, \dots j\}$,
there exists the derivative $\D_1^n \D_2^m g$ and it is continuous,
where $\D_1 g$ is the derivative  of a two variable function $g$ in the direction of the first variable
and $\D_2 g$ is the derivative in the direction of the second variable.
A function $g$ is \emph{$(\infty, j)$-times continuously differentiable}
if $g$ is $(i, j)$-times continuously differentiable for all $i \in \N$.
We write $\classC^{(i,j)}{[A \times B]}$ for the set of 
$(i, j)$-times continuously  differentiable functions from $A \times B$ to $\R$,
and abbreviate it as $\classC^{(i,j)}$ if the domain is obvious.
When a function $g$ is in $\classC^{(i,j)}[A \times B]$,
we write $\D^{(i,j)}g$ for the derivative $\D_1^i \D_2^j g$.
