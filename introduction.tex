\section{Introduction}

Let $g \colon [0,1] \times \R \to \R$ be continuous 
and consider the differential equation 
\begin{align}
 \label{eq:ode}
 h(0) & = 0, &
 \D h(t) & = g(t,h(t)) \quad t \in [0,1], 
\end{align}
where $\D h$ denotes the derivative of $h$. 
How complex can the solution~$h$ be, 
assuming that $g$ is polynomial-time computable? 
Here, polynomial-time computability 
and other notions of complexity 
are from the field of 
\emph{Computable Analysis}~\cite{weihrauch00:_comput_analy}
and measure how hard it is to 
approximate real functions with specified precision 
(Section~\ref{section: preliminaries}). 

If we put no assumption on $g$ other than being polynomial-time computable, 
the solution~$h$ (which is not unique in general) can be non-computable. 
Table~\ref{table:related} summarizes known results about 
the complexity of $h$ under various assumptions 
(that get stronger as we go down the table). 
In particular, if $g$ is (globally) Lipschitz continuous, 
then the (unique) solution $h$ is known to be 
polynomial-space computable but still can be 
$\classPSPACE$-hard \cite{kawamura2010lipschitz}. 
In this paper, we study the complexity of $h$ 
when we put stronger assumptions about 
the smoothness of $g$. 

\begin{table}
\renewcommand\arraystretch{1.3}
\begin{center}
 \caption{The complexity of the solution $h$ of \eqref{eq:ode}
 assuming $g$ is polynomial-time computable.}
 \label{table:related}
 \begin{tabular}{lll}
  Assumptions & Upper bounds & Lower bounds \\
  \hline
   --- & --- & can be all non-computable \cite{pour1979computable} \\
  $h$ is the unique solution & computable \cite{coddington1955theory}
  & \parbox[t]{14em}{can take arbitrarily long time\\\cite{ko1983computational,miller1970recursive}} \\
  the Lipschitz condition  & polynomial-space \cite{ko1983computational}
      &	can be $\classPSPACE$-hard \cite{kawamura2010lipschitz}\\
  $g$ is of class $\classC ^{(\infty, 1)}$ & polynomial-space 
      & \parbox[t]{12em}{can be $\classPSPACE$-hard\\(Theorem~\ref{DifferentiableIsPspace})} \\
  \parbox[t]{10.55em}{$g$ is of class $\classC ^{(\infty, k)}$\\{}(for each constant $k$)}
  & polynomial-space 
  & can be $\classCH$-hard (Theorem~\ref{KTimesIsCH}) \\
  $g$ is analytic
  & polynomial-time \cite{muller1987uniform,ko1988computing,kawamura2010complexity} 
  & ---
 \end{tabular}
\end{center}
\end{table}

In numerical analysis, 
knowledge about smoothness of the input function 
(such as being differentiable enough times) 
is often beneficial 
in applying certain algorithms or simplifying their analysis.
However, 
to our knowledge, 
this casual understanding that smoothness is good 
has not been rigorously substantiated 
in terms of computational complexity theory. 
This motivates us to ask whether, 
for our differential equation \eqref{eq:ode}, 
smoothness really reduces the complexity of the solution. 

One extreme is the case where $g$ is analytic: 
$h$ is then polynomial-time computable 
(the last row of the table) 
by an argument based on Taylor series\footnote{
As shown by M\"uller \cite{muller1987uniform} and 
Ko and Friedman \cite{ko1988computing}, 
polynomial-time computability of an analytic function 
on a compact interval is 
equivalent to that of its Taylor sequence at a point 
(although the latter is a local property, 
polynomial-time computability on the whole interval is implied 
by analytic continuation; 
see \cite[Corollary~4.5]{muller1987uniform}
or \cite[Theorem~11]{kawamura2010complexity}). 
This implies the polynomial-time computability of $h$, 
since we can efficiently compute the 
Taylor sequence of $h$ from that of $g$. 
} (this does not necessarily mean that 
computing the values of $h$ from those of $g$ is easy; 
see the last paragraph of Section~\ref{section: constructive}). 
Thus our interest is in 
the cases between Lipschitz and analytic 
(the fourth and fifth rows). 
We say that $g$ is of class $\classC ^{(i, j)}$
if the partial derivative $\D ^{(n, m)} g$ 
(often also denoted $\partial ^{n + m} g (t, y) / \partial t ^n \partial y ^m$)
exists and is continuous for all $n \le i$ and $m \le j$;%
\footnote{%
Another common terminology is to say that $g$ is of class $\classC ^k$
if it is of class $\classC ^{(i,j)}$ 
for all $i$, $j$ with $i + j \leq k$.}
it is said to be of class $\classC ^{(\infty, j)}$ if
it is of class $\classC ^{(i, j)}$ for all $i \in \N$. 

\begin{theorem}
 \label{DifferentiableIsPspace}
There exists a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, 1)}$ such that
the equation \eqref{eq:ode} has a 
$\classPSPACE$-hard solution $h \colon [0, 1] \to \R$. 
 \end{theorem}

 \begin{theorem}
  \label{KTimesIsCH}
Let $k$ be a positive integer. 
There is a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, k)}$ such that
the equation \eqref{eq:ode} has a 
$\classCH$-hard solution $h \colon [0, 1] \to \R$, 
where $\classCH \subseteq \classPSPACE$ is the 
Counting Hierarchy (see Section~\ref{subsection: counting hierarchy}). 
 \end{theorem}

We said
$g \colon [0,1] \times [-1, 1] \to \R$ instead of 
$g \colon [0,1] \times \R \to \R$, because
the notion of polynomial-time computability of real functions 
in this paper is defined only when the domain is a bounded closed region.%
\footnote{%
Although we could extend our definition to 
functions with unbounded domain~%
\cite[Section~4.1]{kawamura2010operators}, 
the results in Table~\ref{table:related} 
do not hold as they are, 
because polynomial-time compubable functions $g$, 
such as $g (t, y) = y + 1$, 
could yield functions~$h$, such as $h (t) = \exp t - 1$, 
that grow too fast to be polynomial-time (or even polynomial-space) computable. 
Bournez, Gra\c ca and Pouly~%
\cite[Theorem~2]{bournez11:_solvin_analy_differ_equat_in}
report that the statement about the analytic case holds true 
if we restrict the growth of $h$ (and its extention to the complex plane) 
appropriately. 
} 
This makes the equation~\eqref{eq:ode} ill-defined 
in case $h$ ever takes a value outside $[-1, 1]$. 
By saying that $h$ is a solution in Theorem~\ref{DifferentiableIsPspace}, 
we are also claiming that 
$h (t) \in [-1, 1]$ for all $t \in [0, 1]$. 
In any case, 
since we are putting stronger assumptions on $g$ than Lipschitz continuity, 
such a solution $h$, if it exists, is unique. 

Whether smoothness of the input function 
reduces the complexity of the output
has been studied for operators other than solving differential equations, 
and the following negative results are known. 
The integral of a polynomial-time computable real function 
can be $\classNumberP$-hard, and this does not change 
by restricting the input to 
$\classC ^\infty$ (infinitely differentiable) functions
\cite[Theorem~5.33]{ko1991complexity}. 
Similarly, the function obtained by maximization 
from a polynomial-time computable real function 
can be $\classNP$-hard, and this is still so
even if the input function is restricted to $\classC ^\infty$ 
\cite[Theorem~3.7]{ko1991complexity}%
\footnote{%
The proof of this fact in \cite[Theorem 3.7]{ko1991complexity}
needs to be fixed by redefining 
\[f(x) = 
\begin{cases}
 u_s & \text{if not } R(s,t), \\
 u_s + 2^{-(p(n)+2n+1)\cdot n} \cdot h_1(2^{p(n)+2n+1} (x - y_{s,t})) & \text{if } R(s,t). 
\end{cases}\]
}. 
(Restricting to analytic inputs 
renders the output polynomial-time computable, 
again by the argument based on Taylor series.)
In contrast, for the differential equation
we only have Theorem~\ref{KTimesIsCH} for each $k$, 
and do not have any hardness result 
when $g$ is assumed to be infinitely differentiable. 

Theorems \ref{DifferentiableIsPspace} and \ref{KTimesIsCH} 
are about the complexity of each solution $h$. 
We can also talk about 
the complexity of the operator that maps $g$ to $h$; 
see Section~\ref{section: constructive}. 

\subsubsection*{Notation}
Let $\N$, $\Z$, $\Q$, $\R$ denote the set of natural numbers,
integers,
rational numbers and 
real numbers, respectively.

Let $A$ and $B$ be bounded closed intervals in $\R$.
We write $|f| = \sup_{x \in A} f(x)$ for $f \colon A \to \R$.
A function $f \colon A \to \R$ is \emph{of class $\classC^i$}
($i$-times continuously differentiable)
if all the derivatives $\D f, \D^2 f, \dots, \D^i f$ exist and are continuous.

For a differentiable function $g$ of two variables, 
we write $\D _1 g$ and $\D _2 g$ for the derivatives of $g$ 
with respect to the first and the second variable,
respectively.
A function $g \colon A \times B \to \R$ is of \emph{class $\classC^{(i, j)}$}
if for each $n \in \{0, \dots, i\}$ and $m \in \{0, \dots j\}$,
the derivative $\D_1^n \D_2^m g$ exists and is continuous.
A function $g$ is of \emph{class $\classC^{(\infty, j)}$}
if it is of class $\classC^{(i, j)}$ for all $i \in \N$.
When $g$ is of class $\classC^{(i,j)}$,
we write $\D^{(i,j)}g$ for the derivative $\D_1^i \D_2^j g$.
