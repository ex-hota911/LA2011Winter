\section{Other Versions of the Problem}

\subsection{Complexity of the Final Value}
\label{section: final value}
In the previous section, 
we considered the complexity of the solution~$h$ of the ODE as a real function. 
Here we discuss the complexity of the final value $h (1)$ and
relate it to tally languages (subsets of $\{0\}^*$), 
as did 
Ko~\cite{ko1983computational} and 
Kawamura~\cite[Theorem~5.1]{kawamura2010complexity}
for the Lipschitz continuous case.
%i.e., for any tally language $L \in \classPSPACE$,
%there exist functions $g$ and $h$ satisfying \eqref{eq:ode}
%such that $g$ is Lipschitz continuous and polynomial-time computable,
%and $L$ reduces to $h(1)$.
% We show that the final value of ODEs of
% once differentiable functions and fixed times differentiable functions
% are at least as hard as tally $\classPSPACE$ and tally $\classCH$, respectively.

We say that a language~$L$ \emph{reduces to} a real number $x$ 
if there is a polynomial-time oracle Turing machine $M$ 
such that $M^\phi$ accepts $L$ for any name $\phi$ of $x$.
Note that this is the same as 
the reduction in Definition~\ref{definition: reduction}
to a constant function with value~$x$. 


\begin{theorem}
\label{theorem: final value of once}
For any tally language $T \in \classPSPACE$,
there are a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, 1)}$ and 
a function $h \colon [0,1] \to \R$
satisfying \eqref{eq:ode} 
such that $L$ reduces to $h(1)$.
\end{theorem}

\begin{theorem}
\label{theorem: final value of fixed}
Let $k$ be a positive integer. 
For any tally language $T \in \classCH$,
there are a polynomial-time computable function
$g \colon [0,1] \times [-1,1] \to \R$ 
of class $\classC ^{(\infty, k)}$ and 
a function $h \colon [0,1] \to \R$
satisfying \eqref{eq:ode} 
such that $L$ reduces to $h(1)$.
\end{theorem}

We can prove Theorem~\ref{theorem: final value of fixed} 
from Lemma~\ref{KTimesFamily}
in the same way as the proof of \cite[Theorem~5.1]{kawamura2010complexity}.
We skip the proof of Theorem~\ref{theorem: final value of once}
since it is similar.

\begin{proof}
Let $T$ be any tally language in $\classCH$ and $k$ be any positive integer,
and let $L$ and $\mu$ be as Lemma~\ref{KTimesFamily}.
Define $
\lambda(x) = x + 1
$, $
\gamma(x) = \mu(x, x) + x \lambda(x)
$ and let $\rho$, $(g_u)_u$, $(h_u)_u$ be  as in Lemma~\ref{KTimesFamily} 
corresponding to the $\gamma$.
Since $L$ is $\classCH$-complete,
there are a polynomial-time function $F$ such that 
$T (0 ^i) =  L(F(0 ^i))$ for all $i$. 

Let $
l_n = 1 - 2^n
$ and $
\bar{\rho}(n) = \sum^{n-1}_{i = 0} \rho(|F(0 ^i)|)
$.  Define $g$ and $h$ as follows: 
when the first variable is in $[0,1)$, let
\begin{align}
 g \left(l_n + \frac{t}{2^{n+1}}, \frac{2m+(-1)^m y}{2^{2n+\gamma(n)+\bar{\rho}(n)}} \right)
 &=
 \frac{g_{F(0^n)}(t, y)}{2^{n-1+\gamma(n)+\bar{\rho}(n)}} \enspace ,
 \\
 h \left( l_n + \frac{t}{2^{n+1}} \right)
 &=
 \frac{h_{F(0^n)}(t)}{2^{2n+\gamma(n)+\bar{\rho}(n)}}
 + \sum^{n-1}_{i = 0} \frac{T (0^i)}{2^{2 i + \gamma (i) + \bar{\rho} (i + 1)}}
\end{align}
for each $n \in \N$, $t \in [0,1]$, $y \in [-1, 1]$ and $m \in \Z$; 
when the first variable is $1$,
let 
\begin{align} 
  g(1, y) 
&
 =
  0 \enspace, 
\\
\label{equation: final value of h}
  h(1) 
&
 = 
 \sum^\infty_{n = 0} \frac{T (0^n)}{2^{2n+\gamma(n)+\bar{\rho}(n+1)}} \enspace. 
\end{align}
It can be proved similarly to the proof of Theorem~\ref{KTimesIsCH} 
that $g$ is polynomial-time computable and of class $\classC ^{(\infty, k)}$
and that $g$ and $h$ satisfy \eqref{eq:ode}.
The equation \eqref{equation: final value of h} implies 
that $T$ reduces to $h(1)$. 
\qed
\end{proof}


\subsection{Complexity of Operators}
\label{section: constructive}

Both Theorems \ref{DifferentiableIsPspace} and \ref{KTimesIsCH}
state the complexity of the solution $h$ under the assumption 
that $g$ is polynomial-time computable.
But how hard is it to ``solve'' differential equations,
i.e., how complex is the operator that takes $g$ to $h$? 
To make this question precise,
we need to define the complexity of operators 
taking real functions to real functions.

Recall that, to discuss complexity of real functions,
we used string functions as names of elements in $\R$. 
Such an encoding is called a \emph{representation} of $\R$.
Likewise, 
we now want to encode real functions by string functions
to discuss complexity of real operators. 
In other words, we need to define representations of
the class $\classC _{[0, 1]}$ of continuous functions $h \colon [0,1] \to \R$ 
and class $\classLip _{[0, 1] \times [-1, 1]}$ of Lipschitz continuous functions $g \colon [0, 1] \times [-1, 1] \to \R$. 
The notions of computability and complexity depend on these representations.
Following \cite{kawamura2010operators},
we use $\deltabox$ and $\deltaboxLip$ as the 
representations of $\classC_{[0,1]}$ and $\classLip_{[0, 1] \times [-1, 1]}$, 
respectively.
It is known that 
$\deltabox$ is the canonical representation of $\classC_{[0, 1]}$ 
in a certain sense \cite{kawamura11:_funct_space_repres_and_polyn_time_comput}, 
and $\deltaboxLip$ is the representation defined by adding to $\deltabox$
the information on the Lipschitz constant.

Since these representations use string functions 
whose values have variable lengths,
we use \emph{second order polynomials}
to bound the amount of resources (time and space) of machines
\cite{kawamura2010operators}, 
and this leads to the definitions of second-order complexity classes
(e.g. $\classFPSPACEtwo$, polynomial-space computable),
reductions (e.g. $\redW$, polynomial-time Weihrauch reduction), 
and hardness.
Combining them with the representations of real functions mentioned above,
we can restate our theorems in the constructive form as follows.

Let $\OpIVP$ be the operator 
mapping a real function $g \in \classLip_{[0, 1] \times [-1, 1]}$ to
the solution $h \in \classC_{[0, 1]}$ of \eqref{eq:ode}.
The operator $\OpIVP$ is a partial function 
from $\classLip _{[0, 1] \times [-1, 1]}$ to $\classC _{[0, 1]}$
(it is partial because the trajectory may fall out of the interval $[-1, 1]$, 
see the paragraph following Theorem~\ref{KTimesIsCH}).
In \cite[Theorem 4.9]{kawamura2010operators}, the
$(\deltaboxLip, \deltabox)$-$\classFPSPACEtwo$-$\redW$-completeness of $\OpIVP$ 
was proved
by modifying
the proof of the results in the third row of Table~\ref{table:related}.
Theorem~\ref{DifferentiableIsPspace} can be rewritten in a similar way. 
That is, let $\OpIVP _k$ be the operator $\OpIVP$ whose input is restricted to class $\classC^{(\infty, k)}$. Then we have: 

\begin{theorem}
\label{theorem: C1 constructive}
The operator $\OpIVP _1$ is $(\deltaboxLip, \deltabox)$-$\classFPSPACEtwo$-$\redW$-complete.
\end{theorem}

To show this theorem,
we need to verify that the information used to construct functions in the proof of Theorem~\ref{DifferentiableIsPspace}
can be obtained easily from the inputs.
We omit the proof since it does not require any new technique.
Theorem~\ref{theorem: C1 constructive}
automatically implies Theorem~\ref{DifferentiableIsPspace} 
because of \cite[Lemmas 3.7 and 3.8]{kawamura2010operators}. 

% The constructive version of Theorem~\ref{KTimesIsCH} is also true: 
% for each $k \in \N$,
% the restricted operator $\OpIVP _k$ is 
% $(\deltaboxLip, \deltabox)$-$\classCHtwo$-$\redW$-hard.
% But the formulation of this 
% second-order version $\classCHtwo$ of the counting hierarchy 
% requires some discussion on relativized computation, 
% which will appear in a forthcoming paper. 

In contrast, 
the polynomial-time computability in the analytic case
(the last row of Table~\ref{table:related})
is \emph{not} a consequence of a statement based on $\deltabox$. 
It is based on the calculation of the Taylor coefficients, 
and hence we only know how 
to convert the Taylor sequence of $g$ at a point to that of $h$. 
In other words, 
the operator $\OpIVP$ restricted to the analytic functions
is not $(\deltaboxLip, \deltabox)$-$\classFPtwo$-computable, 
but $(\deltaTaylor, \deltaTaylor)$-$\classFPtwo$-computable, 
where $\deltaTaylor$ is the representation that 
encodes an analytic function using its Taylor coefficients at a point 
in a suitable way. 
More discussion on representations of analytic functions 
and the complexity of operators on them 
can be found in 
\cite{kawamura12:_unifor_polyt_comput_operat_univar}. 